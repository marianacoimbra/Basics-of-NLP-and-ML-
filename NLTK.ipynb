{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d8d9850",
   "metadata": {},
   "source": [
    "# NLTK Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d35f78",
   "metadata": {},
   "source": [
    "### Examples to learn the basics of nltk module (Natural Language ToolKit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bd779f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8d07f1",
   "metadata": {},
   "source": [
    "download de alguns módulos específicos do NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "676fd7ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mariv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mariv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mariv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\mariv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cfcdef",
   "metadata": {},
   "source": [
    "## Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9071026c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['God is Great!', 'I won a lottery.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"God is Great! I won a lottery.\"\n",
    "tokenized = sent_tokenize(text)\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5618db78",
   "metadata": {},
   "source": [
    "## Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee793d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['God', 'is', 'Great', '!', 'I', 'won', 'a', 'lottery', '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"God is Great! I won a lottery.\"\n",
    "tokenized = word_tokenize(text)\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc1af69",
   "metadata": {},
   "source": [
    "## Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba6071b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"mustn't\", 'hasn', 'after', 'because', 'while', 'was', 'against', \"aren't\", 'some', 'is', 'each', 'he', 'with', 'can', 'ours', 'by', 'has', 'our', 'she', \"weren't\", 'there', 'aren', 'in', 'ma', 's', 're', 'yourself', \"didn't\", \"needn't\", 'into', 'them', 'shan', 'again', 'if', 'how', \"won't\", 'this', \"haven't\", 'yourselves', 'i', 'which', 'are', 'of', 'same', 'above', 'out', 'my', 'will', 'from', 'own', 'until', 'needn', \"mightn't\", 'were', 'its', 'few', 'weren', 'very', 'theirs', 'why', \"you've\", 't', 'as', 'who', 'or', 'had', 'did', 'on', 'do', \"shan't\", \"you'll\", 'than', 'then', \"should've\", \"that'll\", \"don't\", 'other', 'when', 'and', 'up', 'off', 'yours', 'her', 'any', 'his', 'down', 'more', \"wasn't\", 'won', 'those', 'further', 'once', 'isn', 'no', \"hadn't\", 'doesn', 'don', 'whom', 'it', \"hasn't\", 'below', 'should', 'o', \"isn't\", 'm', \"she's\", \"it's\", 'these', 'before', 'be', 'about', 'not', 'didn', 'having', 'll', 'mustn', 'itself', 'nor', \"you're\", 'their', 'haven', 'doing', 'for', 'ourselves', 'does', 'am', 'both', 'shouldn', 'you', 'y', 'now', 'me', 'your', 'that', \"doesn't\", 'myself', 'under', 'himself', 'been', \"you'd\", 'over', 'wasn', 'being', 'we', \"shouldn't\", 'have', 'couldn', 'they', 'where', 'a', 'd', 'too', 'during', 'hers', 'most', 'here', 'through', \"couldn't\", 'wouldn', \"wouldn't\", 'only', 'all', 'between', 'mightn', 'ain', 'hadn', 'such', 've', 'to', 'so', 'an', 'herself', 'what', 'but', 'just', 'themselves', 'the', 'at', 'him'}\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4d0c853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized words:  ['God', 'is', 'Great', '!', 'I', 'won', 'a', 'lottery', '.']\n",
      "Filtered Sentence:  ['God', 'Great', '!', 'I', 'lottery', '.']\n"
     ]
    }
   ],
   "source": [
    "filtered_words = [word for word in tokenized if word not in stop_words]\n",
    "print(\"Tokenized words: \", tokenized)\n",
    "print(\"Filtered Sentence: \", filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be141f90",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724139fe",
   "metadata": {},
   "source": [
    "Stemming is the process of producing morphological variants of a root/base word. Stemming programs are commonly referred to as stemming algorithms or stemmers. A stemming algorithm reduces the words “chocolates”, “chocolatey”, and “choco” to the root word, “chocolate” and “retrieval”, “retrieved”, “retrieves” reduce to the stem “retrieve”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa54d33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized words:  ['connect', 'connected', 'connecting', 'connection']\n",
      "Stemmed Sentence:  ['connect', 'connect', 'connect', 'connect']\n"
     ]
    }
   ],
   "source": [
    "example_words = ['connect', 'connected', 'connecting', 'connection']\n",
    "ps = PorterStemmer()\n",
    "stemmed_words = [ps.stem(w) for w in example_words]\n",
    "\n",
    "print(\"Tokenized words: \", example_words)\n",
    "print(\"Stemmed Sentence: \", stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c275da",
   "metadata": {},
   "source": [
    "### SnowBall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b444ffa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('arabic', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish')\n"
     ]
    }
   ],
   "source": [
    "print(SnowballStemmer.languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d56242b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized words:  ['conexão', 'conectado', 'conectar', 'conectando']\n",
      "Stemmed Sentence:  ['conexã', 'conect', 'conect', 'conect']\n"
     ]
    }
   ],
   "source": [
    "example_words = ['conexão', 'conectado', 'conectar', 'conectando']\n",
    "ps = SnowballStemmer('portuguese')\n",
    "stemmed_words = [ps.stem(w) for w in example_words]\n",
    "\n",
    "print(\"Tokenized words: \", example_words)\n",
    "print(\"Stemmed Sentence: \", stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2010c6",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41df891",
   "metadata": {},
   "source": [
    "takes into consideration the morphological analysis of the words. To do so, it is necessary to have detailed dictionaries which the algorithm can look through to link the form back to its lemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46b1e365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stone\n",
      "speak\n",
      "are\n",
      "gees\n",
      "went\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "print(stemmer.stem('stones'))\n",
    "print(stemmer.stem('speaking'))\n",
    "print(stemmer.stem('are'))\n",
    "print(stemmer.stem('geese'))\n",
    "print(stemmer.stem('went'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f4dc420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stone\n",
      "speak\n",
      "be\n",
      "goose\n",
      "go\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "print(lemmatizer.lemmatize('stones'))\n",
    "print(lemmatizer.lemmatize('speaking', pos='v'))\n",
    "print(lemmatizer.lemmatize('are', pos='v'))\n",
    "print(lemmatizer.lemmatize('geese'))\n",
    "print(lemmatizer.lemmatize('went', pos='v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61c23a9",
   "metadata": {},
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7448d699",
   "metadata": {},
   "source": [
    "It is a method of identifying words as nouns, verbs, adjectives, adverbs, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66d88a06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: ['Albert', 'Einstein', 'was', 'born', 'in', 'Ulm', ',', 'Germany', 'in', '1879', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Albert', 'NNP'),\n",
       " ('Einstein', 'NNP'),\n",
       " ('was', 'VBD'),\n",
       " ('born', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('Ulm', 'NNP'),\n",
       " (',', ','),\n",
       " ('Germany', 'NNP'),\n",
       " ('in', 'IN'),\n",
       " ('1879', 'CD'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"Albert Einstein was born in Ulm, Germany in 1879.\"\n",
    "\n",
    "tokens = nltk.word_tokenize(sent)\n",
    "print(\"Sentence:\", tokens)\n",
    "\n",
    "nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1271dcb3",
   "metadata": {},
   "source": [
    "## N-Gram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38715cd8",
   "metadata": {},
   "source": [
    "N-gram can be defined as the contiguous sequence of n items from a given sample of text or speech. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7335eca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('God', 'is'), ('is', 'Great'), ('Great', '!'), ('!', 'I'), ('I', 'won'), ('won', 'a'), ('a', 'lottery'), ('lottery', '.')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import bigrams\n",
    "string_bigrams = list(bigrams(tokenized))\n",
    "print(string_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eda41f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
